"""
æŠ€æœ¯é—®é¢˜æ±‚è§£åè°ƒå™¨

åè°ƒæ•´ä¸ªé—®é¢˜æ±‚è§£æµç¨‹ï¼š
1. æ„å›¾åˆ†æ
2. ä¸“å®¶åŒ¹é…
3. å¹¶è¡Œæ±‚è§£
4. æ•´åˆç­”æ¡ˆ
"""
import asyncio
from typing import List, Dict, Any, Optional, AsyncIterator
from dataclasses import dataclass, field, asdict
import json
import time

from .intent_analyzer import IntentAnalyzer, ProblemIntent
from .expert_matcher import ExpertMatcher, MatchedExpert


@dataclass
class SubProblemSolution:
    """å­é—®é¢˜è§£å†³æ–¹æ¡ˆ"""
    expert_name: str
    expert_role: str
    sub_problem: str
    solution: str
    model: str = ""  # ä½¿ç”¨çš„æ¨¡å‹
    confidence: float = 0.0
    duration_ms: float = 0
    
    def to_dict(self) -> dict:
        return asdict(self)


@dataclass
class ProblemSolution:
    """å®Œæ•´é—®é¢˜è§£å†³æ–¹æ¡ˆ"""
    original_problem: str
    intent: ProblemIntent
    matched_experts: List[MatchedExpert]
    sub_solutions: List[SubProblemSolution]
    final_solution: str
    total_duration_ms: float = 0
    
    def to_dict(self) -> dict:
        return {
            "original_problem": self.original_problem,
            "intent": self.intent.to_dict(),
            "matched_experts": [
                {"name": e.name, "role": e.role, "domain": e.matched_domain, "sub_problem": e.assigned_sub_problem}
                for e in self.matched_experts
            ],
            "sub_solutions": [s.to_dict() for s in self.sub_solutions],
            "final_solution": self.final_solution,
            "total_duration_ms": self.total_duration_ms
        }
    
    def to_json(self) -> str:
        return json.dumps(self.to_dict(), ensure_ascii=False, indent=2)


class TechnicalProblemSolver:
    """
    æŠ€æœ¯é—®é¢˜æ±‚è§£ä¸“å®¶
    
    å®Œæ•´æµç¨‹ï¼š
    1. æ„å›¾åˆ†æ - ç†è§£é—®é¢˜ï¼Œè¯†åˆ«é¢†åŸŸ
    2. é—®é¢˜åˆ†è§£ - å°†å¤æ‚é—®é¢˜æ‹†è§£
    3. ä¸“å®¶åŒ¹é… - é€‰æ‹©åˆé€‚çš„ä¸“å®¶
    4. å¹¶è¡Œæ±‚è§£ - å„ä¸“å®¶åŒæ—¶å¤„ç†å­é—®é¢˜
    5. æ•´åˆç­”æ¡ˆ - ç»¼åˆå½¢æˆæœ€ç»ˆæ–¹æ¡ˆ
    
    ä½¿ç”¨ç¤ºä¾‹:
        solver = TechnicalProblemSolver(llm_client)
        solution = await solver.solve("ç©ºè°ƒå™ªéŸ³å¤§å¦‚ä½•è§£å†³ï¼Ÿ")
        print(solution.final_solution)
    """
    
    def __init__(self, llm_client, expert_catalog: List = None):
        self.llm_client = llm_client
        self.intent_analyzer = IntentAnalyzer(llm_client)
        self.expert_matcher = ExpertMatcher(expert_catalog)
    
    async def solve(
        self, 
        problem: str,
        selected_expert_indices: List[int] = None,
        max_experts: int = 5
    ) -> ProblemSolution:
        """
        æ±‚è§£æŠ€æœ¯é—®é¢˜ï¼ˆå®Œæ•´æµç¨‹ï¼‰
        
        Args:
            problem: æŠ€æœ¯é—®é¢˜æè¿°
            selected_expert_indices: ç”¨æˆ·é¢„é€‰çš„ä¸“å®¶ç´¢å¼•ï¼ˆå¯é€‰ï¼‰
            max_experts: æœ€å¤šä½¿ç”¨çš„ä¸“å®¶æ•°é‡
        
        Returns:
            å®Œæ•´çš„é—®é¢˜è§£å†³æ–¹æ¡ˆ
        """
        start_time = time.time()
        
        # 1. æ„å›¾åˆ†æ
        intent = await self.intent_analyzer.analyze(problem)
        
        # 2. ä¸“å®¶åŒ¹é…
        if selected_expert_indices:
            # ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„ä¸“å®¶
            matched_experts = []
            for idx in selected_expert_indices[:max_experts]:
                expert = self.expert_matcher.get_expert_by_index(idx)
                if expert:
                    matched_experts.append(MatchedExpert(
                        index=idx,
                        name=expert.name,
                        role=expert.role,
                        expertise=expert.expertise,
                        matched_domain="ç”¨æˆ·æŒ‡å®š",
                        relevance_score=1.0
                    ))
        else:
            # è‡ªåŠ¨åŒ¹é…
            matched_experts = self.expert_matcher.match_with_sub_problems(
                domains=intent.domains,
                sub_problems=intent.sub_problems,
                limit=max_experts
            )
        
        if not matched_experts:
            # å›é€€åˆ°é»˜è®¤ä¸“å®¶
            matched_experts = self.expert_matcher.match_by_domains(["äº§å“è§„åˆ’"], limit=1)
        
        # 3. å¹¶è¡Œæ±‚è§£
        sub_solutions = await self._solve_parallel(problem, intent, matched_experts)
        
        # 4. æ•´åˆç­”æ¡ˆ
        final_solution = await self._integrate_solutions(problem, intent, sub_solutions)
        
        total_duration = (time.time() - start_time) * 1000
        
        return ProblemSolution(
            original_problem=problem,
            intent=intent,
            matched_experts=matched_experts,
            sub_solutions=sub_solutions,
            final_solution=final_solution,
            total_duration_ms=total_duration
        )
    
    async def solve_stream(
        self,
        problem: str,
        selected_expert_indices: List[int] = None,
        max_experts: int = 5,
        iteration_rounds: int = 1  # è¿­ä»£è½®æ•°ï¼Œ1=æ— è¿­ä»£ï¼Œ2+=åæ€éªŒè¯
    ) -> AsyncIterator[Dict[str, Any]]:
        """
        æµå¼æ±‚è§£ - é€æ­¥è¿”å›ç»“æœï¼Œæ”¯æŒè¿­ä»£åæ€
        
        Yields:
            {"stage": "analyzing", "data": {...}}
            {"stage": "matching", "data": {...}}
            {"stage": "solving", "expert": "...", "solution": "..."}
            {"stage": "reflection", "round": N, "feedback": "..."}  # æ–°å¢
            {"stage": "integrating", "data": {...}}
            {"stage": "complete", "data": {...}}
        """
        start_time = time.time()
        
        # 1. æ„å›¾åˆ†æ
        yield {"stage": "analyzing", "message": "æ­£åœ¨åˆ†æé—®é¢˜æ„å›¾..."}
        intent = await self.intent_analyzer.analyze(problem)
        yield {
            "stage": "analyzed", 
            "data": {
                "problem_type": intent.problem_type,
                "domains": intent.domains,
                "sub_problems": intent.sub_problems,
                "complexity": intent.complexity
            }
        }
        
        # 2. ä¸“å®¶åŒ¹é…
        yield {"stage": "matching", "message": "æ­£åœ¨åŒ¹é…ä¸“å®¶..."}
        if selected_expert_indices:
            matched_experts = []
            for idx in selected_expert_indices[:max_experts]:
                expert = self.expert_matcher.get_expert_by_index(idx)
                if expert:
                    matched_experts.append(MatchedExpert(
                        index=idx,
                        name=expert.name,
                        role=expert.role,
                        expertise=expert.expertise,
                        matched_domain="ç”¨æˆ·æŒ‡å®š",
                        relevance_score=1.0
                    ))
        else:
            matched_experts = self.expert_matcher.match_with_sub_problems(
                domains=intent.domains,
                sub_problems=intent.sub_problems,
                limit=max_experts
            )
        
        yield {
            "stage": "matched",
            "data": {
                "experts": [
                    {"name": e.name, "role": e.role, "domain": e.matched_domain}
                    for e in matched_experts
                ]
            }
        }
        
        # 3. å¹¶è¡Œæ±‚è§£
        yield {"stage": "solving", "message": f"æ­£åœ¨å¹¶è¡Œæ±‚è§£ï¼ˆ{len(matched_experts)}ä½ä¸“å®¶ï¼‰..."}
        
        sub_solutions = []
        tasks = []
        
        for expert in matched_experts:
            task = self._solve_single(problem, intent, expert)
            tasks.append((expert, task))
        
        # å¹¶è¡Œæ‰§è¡Œï¼Œé€ä¸ªè¿”å›ç»“æœ
        results = await asyncio.gather(*[t[1] for t in tasks])
        
        for i, (expert, _) in enumerate(tasks):
            solution = results[i]
            sub_solutions.append(solution)
            yield {
                "stage": "expert_done",
                "expert": expert.name,
                "role": expert.role,
                "model": solution.model,
                "domain": expert.matched_domain,
                "solution": solution.solution  # å®Œæ•´è¾“å‡ºï¼Œä¸æˆªæ–­
            }
        
        # 4. è¿­ä»£åæ€éªŒè¯ï¼ˆå¦‚æœ iteration_rounds > 1ï¼‰
        current_solutions = sub_solutions
        for round_num in range(2, iteration_rounds + 1):
            yield {
                "stage": "reflection_start",
                "round": round_num,
                "message": f"ğŸ”„ å¼€å§‹ç¬¬ {round_num} è½®åæ€éªŒè¯..."
            }
            
            # 4a. åæ€é˜¶æ®µ - è¯„ä¼°å½“å‰æ–¹æ¡ˆ
            reflection = await self._reflect_on_solutions(problem, intent, current_solutions)
            yield {
                "stage": "reflection",
                "round": round_num,
                "feedback": reflection[:300] + "..." if len(reflection) > 300 else reflection
            }
            
            # 4b. æ”¹è¿›é˜¶æ®µ - æ ¹æ®åæ€ä¼˜åŒ–æ–¹æ¡ˆ
            improved_solutions = await self._improve_solutions(
                problem, intent, current_solutions, reflection, matched_experts
            )
            
            for i, (expert, improved) in enumerate(zip(matched_experts, improved_solutions)):
                yield {
                    "stage": "improvement",
                    "round": round_num,
                    "expert": expert.name,
                    "improved": improved.solution[:150] + "..." if len(improved.solution) > 150 else improved.solution
                }
            
            current_solutions = improved_solutions
            
            # 4c. éªŒè¯é˜¶æ®µ
            validation = await self._validate_solutions(problem, intent, current_solutions)
            yield {
                "stage": "validation",
                "round": round_num,
                "result": validation
            }
        
        # 5. ä¸“å®¶è®¨è®ºè½®ï¼ˆå¦‚æœ iteration_rounds >= 2ï¼‰
        all_discussions = []
        if iteration_rounds >= 2:
            yield {"stage": "discussion_start", "message": "ğŸ’¬ å¼€å§‹ä¸“å®¶è®¨è®º..."}
            
            discussions = await self._run_discussion_round(
                problem, intent, current_solutions, matched_experts, round_num=1
            )
            all_discussions = discussions
            
            for d in discussions:
                yield {
                    "stage": "discussion",
                    "expert": d["expert"],
                    "role": d["role"],
                    "comment": d["comment"]
                }
        
        # 6. æ‰¹è¯„ä¸è¾©è®ºè½®
        critique_result = {}
        if iteration_rounds >= 2:
            yield {"stage": "critique_start", "message": "âš”ï¸ å¼€å§‹æŠ€æœ¯æ‰¹è¯„ä¸è¾©è®º..."}
            
            critique_result = await self._run_critique_round(
                problem, intent, current_solutions, matched_experts
            )
            
            yield {
                "stage": "critique",
                "critique": critique_result["critique"]
            }
            
            for resp in critique_result.get("responses", []):
                yield {
                    "stage": "critique_response",
                    "expert": resp["expert"],
                    "response": resp["response"]
                }
        
        # 7. å¤šç»´åº¦è¯„ä¼°
        if iteration_rounds >= 2:
            yield {"stage": "evaluation_start", "message": "ğŸ“Š å¼€å§‹å¤šç»´åº¦è¯„ä¼°..."}
            
            evaluation = await self._run_evaluation(
                problem, intent, current_solutions, all_discussions, critique_result
            )
            
            yield {
                "stage": "evaluation",
                "data": evaluation
            }
        
        # 8. æ•´åˆæœ€ç»ˆç­”æ¡ˆ
        yield {"stage": "integrating", "message": "æ­£åœ¨æ•´åˆæœ€ç»ˆè§£å†³æ–¹æ¡ˆ..."}
        final_solution = await self._integrate_solutions(problem, intent, current_solutions)
        
        total_duration = (time.time() - start_time) * 1000
        
        yield {
            "stage": "complete",
            "data": {
                "final_solution": final_solution,
                "total_duration_ms": total_duration,
                "expert_count": len(matched_experts),
                "iteration_rounds": iteration_rounds
            }
        }
    
    async def _solve_single(
        self, 
        problem: str, 
        intent: ProblemIntent,
        expert: MatchedExpert
    ) -> SubProblemSolution:
        """å•ä¸ªä¸“å®¶æ±‚è§£"""
        start_time = time.time()
        
        sub_problem = expert.assigned_sub_problem or problem
        
        prompt = f"""ã€æŠ€æœ¯é—®é¢˜æ·±åº¦åˆ†æä¸æ±‚è§£ã€‘

ä½ æ˜¯{expert.name}ï¼Œä¸“ä¸šé¢†åŸŸæ˜¯{expert.expertise}ã€‚
è¯·å¯¹ä»¥ä¸‹é—®é¢˜è¿›è¡Œ**æ·±å…¥ã€å…¨é¢ã€ç³»ç»Ÿ**çš„åˆ†æï¼Œå±•ç¤ºå®Œæ•´çš„æ¨ç†è¿‡ç¨‹ã€‚

ã€åŸå§‹é—®é¢˜ã€‘
{problem}

ã€é—®é¢˜ç±»å‹ã€‘{intent.problem_type}
ã€ä½ è´Ÿè´£çš„å­é—®é¢˜ã€‘
{sub_problem}

ã€åˆ†æè¦æ±‚ã€‘
è¯·æŒ‰ä»¥ä¸‹ç»“æ„è¾“å‡ºï¼Œ**ä¸é™åˆ¶å­—æ•°**ï¼ŒåŠ¡å¿…è¯¦å°½å®Œæ•´ï¼š

## 1. é—®é¢˜ç†è§£ä¸æ¨ç†è¿‡ç¨‹
- é¦–å…ˆï¼Œé˜è¿°ä½ å¯¹è¿™ä¸ªé—®é¢˜çš„ç†è§£
- å±•ç¤ºä½ çš„æ€è€ƒè¿‡ç¨‹ï¼šä¸ºä»€ä¹ˆä¼šå‡ºç°è¿™ä¸ªé—®é¢˜ï¼Ÿ
- åˆ—å‡ºå…³é”®çš„æŠ€æœ¯è¦ç´ å’Œçº¦æŸæ¡ä»¶
- è¯´æ˜ä½ çš„æ¨ç†é“¾æ¡ï¼šä»é—®é¢˜åˆ°è§£å†³æ–¹æ¡ˆçš„é€»è¾‘è·¯å¾„

## 2. æ ¹å› åˆ†æ
- ä»ä½ çš„ä¸“ä¸šè§’åº¦ï¼Œæ·±å…¥åˆ†æé—®é¢˜äº§ç”Ÿçš„æ ¹æœ¬åŸå› 
- æ¶‰åŠçš„æŠ€æœ¯åŸç†ã€ç‰©ç†æœºåˆ¶ã€ç³»ç»Ÿæœºç†
- éšè—å› ç´ å’Œå®¹æ˜“è¢«å¿½è§†çš„å…³é”®ç‚¹
- é—®é¢˜çš„ç›¸äº’å…³è”æ€§å’Œç³»ç»Ÿæ€§å½±å“

## 3. è¯¦ç»†è§£å†³æ–¹æ¡ˆ
é’ˆå¯¹æ¯ä¸ªå¯è¡Œæ–¹æ¡ˆï¼Œè¯·è¯¦ç»†è¯´æ˜ï¼š
- **æ–¹æ¡ˆæè¿°**ï¼šå…·ä½“åšä»€ä¹ˆã€æ€ä¹ˆåš
- **æŠ€æœ¯åŸç†**ï¼šä¸ºä»€ä¹ˆè¿™ä¸ªæ–¹æ¡ˆæœ‰æ•ˆ
- **å®æ–½æ­¥éª¤**ï¼šè¯¦ç»†çš„æ‰§è¡Œæ­¥éª¤ï¼Œå¯æ“ä½œ
- **æ‰€éœ€èµ„æº**ï¼šæŠ€æœ¯ã€è®¾å¤‡ã€ææ–™ã€äººåŠ›
- **é¢„æœŸæ•ˆæœ**ï¼šé‡åŒ–çš„æ”¹å–„é¢„æœŸ
- **ä¼˜ç¼ºç‚¹åˆ†æ**ï¼šå®¢è§‚è¯„ä¼°

## 4. é£é™©è¯„ä¼°ä¸åº”å¯¹
- æ¯ä¸ªæ–¹æ¡ˆå¯èƒ½é‡åˆ°çš„æŠ€æœ¯éšœç¢
- å®æ–½è¿‡ç¨‹ä¸­çš„é£é™©ç‚¹åŠæ¦‚ç‡
- åº”æ€¥é¢„æ¡ˆå’Œå…œåº•æªæ–½
- å¤±è´¥åçš„å›é€€ç­–ç•¥

## 5. è·¨é¢†åŸŸåä½œ
- éœ€è¦å“ªäº›å…¶ä»–ä¸“ä¸šé…åˆ
- å…·ä½“çš„æ¥å£å®šä¹‰å’Œäº¤ä»˜ç‰©
- åä½œæ—¶åºå’Œé‡Œç¨‹ç¢‘
- æ²Ÿé€šåè°ƒè¦ç‚¹

## 6. ç»“è®ºä¸å»ºè®®
- ç»¼åˆæ¨èçš„æœ€ä¼˜æ–¹æ¡ˆ
- å®æ–½ä¼˜å…ˆçº§å»ºè®®
- é•¿æœŸä¼˜åŒ–æ–¹å‘

è¯·ç»™å‡ºä½ çš„å®Œæ•´ä¸“ä¸šè§£ç­”ï¼Œå±•ç¤ºä¸“å®¶çº§çš„æ·±åº¦æ€è€ƒï¼š"""
        
        # ä½¿ç”¨ gemini-3-pro-preview ä½œä¸ºé»˜è®¤æ¨¡å‹
        model = "gemini-3-pro-preview"
        
        try:
            solution = await self.llm_client.get_completion_async(
                system_prompt=f"ä½ æ˜¯{expert.role}ï¼Œæ“…é•¿{expert.expertise}ã€‚è¯·å±•ç¤ºå®Œæ•´çš„æ¨ç†è¿‡ç¨‹ï¼Œç»™å‡ºè¯¦å°½ã€ä¸“ä¸šã€å¯æ“ä½œçš„è§£å†³æ–¹æ¡ˆã€‚ä¸è¦é™åˆ¶ç¯‡å¹…ï¼Œç¡®ä¿æ–¹æ¡ˆå®Œæ•´ã€‚",
                user_prompt=prompt,
                model=model
            )
        except Exception as e:
            solution = f"[æ±‚è§£å¤±è´¥] {str(e)}"
        
        duration = (time.time() - start_time) * 1000
        
        return SubProblemSolution(
            expert_name=expert.name,
            expert_role=expert.role,
            sub_problem=sub_problem,
            solution=solution,
            model=model,
            confidence=0.8,
            duration_ms=duration
        )
    
    async def _solve_parallel(
        self,
        problem: str,
        intent: ProblemIntent,
        experts: List[MatchedExpert]
    ) -> List[SubProblemSolution]:
        """å¹¶è¡Œæ±‚è§£æ‰€æœ‰å­é—®é¢˜"""
        tasks = [
            self._solve_single(problem, intent, expert)
            for expert in experts
        ]
        return await asyncio.gather(*tasks)
    
    async def _integrate_solutions(
        self,
        problem: str,
        intent: ProblemIntent,
        sub_solutions: List[SubProblemSolution]
    ) -> str:
        """æ•´åˆå„ä¸“å®¶çš„è§£å†³æ–¹æ¡ˆ"""
        solutions_text = "\n\n".join([
            f"ã€{s.expert_name}ï¼ˆ{s.expert_role}ï¼‰ã€‘\n{s.solution}"
            for s in sub_solutions
        ])
        
        prompt = f"""è¯·æ•´åˆä»¥ä¸‹å„ä¸“å®¶çš„è§£å†³æ–¹æ¡ˆï¼Œå½¢æˆä¸€ä»½å®Œæ•´çš„æŠ€æœ¯è§£å†³æ–¹æ¡ˆã€‚

ã€åŸå§‹é—®é¢˜ã€‘
{problem}

ã€é—®é¢˜ç±»å‹ã€‘{intent.problem_type}
ã€æ¶‰åŠé¢†åŸŸã€‘{", ".join(intent.domains)}

ã€å„ä¸“å®¶è§£ç­”ã€‘
{solutions_text}

ã€æ•´åˆè¦æ±‚ã€‘
è¯·ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„è§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ï¼š

## ğŸ“‹ é—®é¢˜æ‘˜è¦
ç®€è¿°é—®é¢˜æ ¸å¿ƒ

## ğŸ¯ è§£å†³æ–¹æ¡ˆ
æ•´åˆå„ä¸“å®¶å»ºè®®ï¼Œå½¢æˆå¯æ‰§è¡Œçš„æ–¹æ¡ˆ

## ğŸ“ å®æ–½æ­¥éª¤
1. ...
2. ...

## âš ï¸ æ³¨æ„äº‹é¡¹
å…³é”®é£é™©å’Œæ³¨æ„ç‚¹

## ğŸ’¡ åç»­ä¼˜åŒ–å»ºè®®
å¯é€‰çš„è¿›ä¸€æ­¥æ”¹è¿›æ–¹å‘

è¯·ç”¨ä¸­æ–‡è¾“å‡ºï¼š"""
        
        try:
            result = await self.llm_client.get_completion_async(
                system_prompt="ä½ æ˜¯æŠ€æœ¯æ–¹æ¡ˆæ•´åˆä¸“å®¶ï¼Œæ“…é•¿ç»¼åˆå¤šä¸ªä¸“ä¸šé¢†åŸŸçš„æ„è§å½¢æˆå¯æ‰§è¡Œæ–¹æ¡ˆã€‚",
                user_prompt=prompt,
                model="gemini-3-pro-preview"
            )
            return result
        except Exception as e:
            # ç®€å•æ‹¼æ¥
            return f"## ç»¼åˆè§£å†³æ–¹æ¡ˆ\n\n{solutions_text}"
    
    async def _reflect_on_solutions(
        self,
        problem: str,
        intent: ProblemIntent,
        solutions: List[SubProblemSolution]
    ) -> str:
        """åæ€è¯„ä¼°å½“å‰æ–¹æ¡ˆ"""
        solutions_text = "\n".join([
            f"ã€{s.expert_name}ã€‘{s.solution[:200]}"
            for s in solutions
        ])
        
        prompt = f"""è¯·å¯¹ä»¥ä¸‹æŠ€æœ¯é—®é¢˜çš„è§£å†³æ–¹æ¡ˆè¿›è¡Œåæ€è¯„ä¼°ï¼š

ã€åŸå§‹é—®é¢˜ã€‘{problem}
ã€é—®é¢˜ç±»å‹ã€‘{intent.problem_type}

ã€å½“å‰æ–¹æ¡ˆã€‘
{solutions_text}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåæ€ï¼š
1. æ–¹æ¡ˆçš„å®Œæ•´æ€§ - æ˜¯å¦è¦†ç›–äº†æ‰€æœ‰å…³é”®ç‚¹ï¼Ÿ
2. å¯è¡Œæ€§ - å®æ–½éš¾åº¦å’Œèµ„æºéœ€æ±‚å¦‚ä½•ï¼Ÿ
3. æ½œåœ¨é£é™© - å¯èƒ½å­˜åœ¨ä»€ä¹ˆé—®é¢˜ï¼Ÿ
4. åˆ›æ–°æ€§ - æœ‰æ²¡æœ‰æ›´å¥½çš„æ€è·¯ï¼Ÿ
5. ååŒæ€§ - å„ä¸“å®¶æ–¹æ¡ˆæ˜¯å¦ç›¸äº’é…åˆï¼Ÿ

è¯·ç»™å‡ºå…·ä½“çš„æ”¹è¿›å»ºè®®ï¼ˆ200å­—ä»¥å†…ï¼‰ï¼š"""
        
        try:
            return await self.llm_client.get_completion_async(
                system_prompt="ä½ æ˜¯æŠ€æœ¯æ–¹æ¡ˆè¯„å®¡ä¸“å®¶ï¼Œæ“…é•¿å‘ç°é—®é¢˜å¹¶æå‡ºæ”¹è¿›å»ºè®®ã€‚",
                user_prompt=prompt,
                model="gemini-3-pro-preview"
            )
        except Exception as e:
            return f"åæ€å¤±è´¥: {str(e)}"
    
    async def _improve_solutions(
        self,
        problem: str,
        intent: ProblemIntent,
        solutions: List[SubProblemSolution],
        reflection: str,
        experts: List[MatchedExpert]
    ) -> List[SubProblemSolution]:
        """æ ¹æ®åæ€æ”¹è¿›æ–¹æ¡ˆ"""
        improved = []
        
        for solution, expert in zip(solutions, experts):
            prompt = f"""æ ¹æ®åæ€æ„è§ï¼Œä¼˜åŒ–ä½ ä¹‹å‰çš„æ–¹æ¡ˆï¼š

ã€åŸå§‹é—®é¢˜ã€‘{problem}
ã€ä½ ä¹‹å‰çš„æ–¹æ¡ˆã€‘{solution.solution}

ã€åæ€æ„è§ã€‘{reflection}

è¯·ä¼˜åŒ–ä½ çš„æ–¹æ¡ˆï¼Œæå‡å®Œæ•´æ€§ã€å¯è¡Œæ€§ã€æ¶ˆé™¤é£é™©ï¼ˆ150å­—ä»¥å†…ï¼‰ï¼š"""
            
            try:
                improved_solution = await self.llm_client.get_completion_async(
                    system_prompt=f"ä½ æ˜¯{expert.role}ï¼Œè¯·æ ¹æ®åé¦ˆä¼˜åŒ–æ–¹æ¡ˆã€‚",
                    user_prompt=prompt,
                    model="gemini-3-pro-preview"
                )
                improved.append(SubProblemSolution(
                    expert_name=solution.expert_name,
                    expert_role=solution.expert_role,
                    sub_problem=solution.sub_problem,
                    solution=improved_solution,
                    model="gemini-3-pro-preview",
                    confidence=0.9,
                    duration_ms=0
                ))
            except:
                improved.append(solution)
        
        return improved
    
    async def _validate_solutions(
        self,
        problem: str,
        intent: ProblemIntent,
        solutions: List[SubProblemSolution]
    ) -> dict:
        """éªŒè¯æ”¹è¿›åçš„æ–¹æ¡ˆ"""
        solutions_text = "\n".join([
            f"ã€{s.expert_name}ã€‘{s.solution[:150]}"
            for s in solutions
        ])
        
        prompt = f"""éªŒè¯ä»¥ä¸‹æŠ€æœ¯æ–¹æ¡ˆæ˜¯å¦æ»¡è¶³è¦æ±‚ï¼š

ã€åŸå§‹é—®é¢˜ã€‘{problem}
ã€æ–¹æ¡ˆã€‘
{solutions_text}

è¯·è¯„ä¼°ï¼š
1. æ˜¯å¦è§£å†³äº†æ ¸å¿ƒé—®é¢˜ï¼Ÿï¼ˆæ˜¯/éƒ¨åˆ†/å¦ï¼‰
2. å®æ–½å¯è¡Œæ€§ï¼Ÿï¼ˆé«˜/ä¸­/ä½ï¼‰
3. è¿˜æœ‰é—æ¼å—ï¼Ÿï¼ˆæœ‰/æ— ï¼‰

è¯·ç”¨JSONæ ¼å¼è¿”å›ï¼Œåªè¿”å›JSONï¼š
{{"solved": "æ˜¯/éƒ¨åˆ†/å¦", "feasibility": "é«˜/ä¸­/ä½", "gaps": "æœ‰/æ— ", "score": 0-100}}"""
        
        try:
            result = await self.llm_client.get_completion_async(
                system_prompt="ä½ æ˜¯æŠ€æœ¯æ–¹æ¡ˆéªŒè¯ä¸“å®¶ï¼Œåªè¿”å›JSONã€‚",
                user_prompt=prompt,
                model="gemini-3-pro-preview"
            )
            # Try to parse JSON
            import re
            json_match = re.search(r'\{[^}]+\}', result)
            if json_match:
                return json.loads(json_match.group())
            return {"solved": "éƒ¨åˆ†", "feasibility": "ä¸­", "gaps": "æœ‰", "score": 70}
        except:
            return {"solved": "éƒ¨åˆ†", "feasibility": "ä¸­", "gaps": "æœ‰", "score": 70}
    
    async def _run_discussion_round(
        self,
        problem: str,
        intent: ProblemIntent,
        solutions: List[SubProblemSolution],
        experts: List[MatchedExpert],
        round_num: int
    ) -> List[dict]:
        """
        ä¸“å®¶è®¨è®ºè½® - æ¯ä½ä¸“å®¶çœ‹åˆ°å…¶ä»–ä¸“å®¶çš„æ–¹æ¡ˆå¹¶è¯„è®º
        
        Returns:
            List of discussion comments from each expert
        """
        # æ„å»ºæ‰€æœ‰æ–¹æ¡ˆæ‘˜è¦
        all_solutions_text = "\n\n".join([
            f"ã€{s.expert_name}çš„æ–¹æ¡ˆã€‘\n{s.solution[:500]}"
            for s in solutions
        ])
        
        discussions = []
        
        for i, (expert, solution) in enumerate(zip(experts, solutions)):
            # å…¶ä»–ä¸“å®¶çš„æ–¹æ¡ˆ
            other_solutions = [s for j, s in enumerate(solutions) if j != i]
            others_text = "\n\n".join([
                f"ã€{s.expert_name}ã€‘{s.solution[:400]}"
                for s in other_solutions
            ])
            
            prompt = f"""ã€ä¸“å®¶è®¨è®º - ç¬¬{round_num}è½®ã€‘

ä½ æ˜¯{expert.name}ï¼Œä½ å·²ç»ç»™å‡ºäº†è‡ªå·±çš„åˆæ­¥æ–¹æ¡ˆã€‚
ç°åœ¨è¯·è¯„è®ºå…¶ä»–ä¸“å®¶çš„æ–¹æ¡ˆï¼Œå¹¶å®Œå–„ä½ è‡ªå·±çš„æ€è·¯ã€‚

ã€åŸå§‹é—®é¢˜ã€‘{problem}

ã€ä½ çš„æ–¹æ¡ˆæ‘˜è¦ã€‘
{solution.solution[:400]}

ã€å…¶ä»–ä¸“å®¶çš„æ–¹æ¡ˆã€‘
{others_text}

ã€è®¨è®ºè¦æ±‚ã€‘
1. å¯¹å…¶ä»–ä¸“å®¶æ–¹æ¡ˆçš„**ä¼˜ç‚¹**è¿›è¡Œè‚¯å®šï¼ˆ50å­—ï¼‰
2. æŒ‡å‡ºå…¶ä»–æ–¹æ¡ˆçš„**æ½œåœ¨é—®é¢˜æˆ–ä¸è¶³**ï¼ˆ100å­—ï¼‰
3. æå‡º**å»ºè®¾æ€§è¡¥å……å»ºè®®**ï¼ˆ100å­—ï¼‰
4. è¯´æ˜ä½ çš„æ–¹æ¡ˆå¦‚ä½•ä¸å…¶ä»–æ–¹æ¡ˆ**ååŒé…åˆ**ï¼ˆ50å­—ï¼‰

è¯·ç›´æ¥è¾“å‡ºä½ çš„è¯„è®ºï¼š"""
            
            try:
                comment = await self.llm_client.get_completion_async(
                    system_prompt=f"ä½ æ˜¯{expert.role}ï¼Œæ­£åœ¨ä¸å…¶ä»–ä¸“å®¶è¿›è¡ŒæŠ€æœ¯è®¨è®ºã€‚ä¿æŒä¸“ä¸šã€å®¢è§‚ã€å»ºè®¾æ€§ã€‚",
                    user_prompt=prompt,
                    model="gemini-3-pro-preview"
                )
                discussions.append({
                    "expert": expert.name,
                    "role": expert.role,
                    "comment": comment
                })
            except Exception as e:
                discussions.append({
                    "expert": expert.name,
                    "role": expert.role,
                    "comment": f"[è®¨è®ºå¤±è´¥] {str(e)}"
                })
        
        return discussions
    
    async def _run_critique_round(
        self,
        problem: str,
        intent: ProblemIntent,
        solutions: List[SubProblemSolution],
        experts: List[MatchedExpert]
    ) -> dict:
        """
        æ‰¹è¯„ä¸è¾©è®ºè½® - æ‰¹è¯„è€…æŒ‘æˆ˜æ‰€æœ‰æ–¹æ¡ˆï¼Œä¸“å®¶å›åº”
        
        Returns:
            {"critique": str, "responses": [{"expert": str, "response": str}]}
        """
        # æ„å»ºæ–¹æ¡ˆæ‘˜è¦
        solutions_text = "\n\n".join([
            f"ã€{s.expert_name}ã€‘\n{s.solution[:400]}"
            for s in solutions
        ])
        
        # 1. æ‰¹è¯„è€…æå‡ºæŒ‘æˆ˜
        critique_prompt = f"""ã€æŠ€æœ¯æ–¹æ¡ˆæ‰¹è¯„ã€‘

ä½œä¸ºç‹¬ç«‹çš„æŠ€æœ¯è¯„å®¡ä¸“å®¶ï¼Œè¯·å¯¹ä»¥ä¸‹è§£å†³æ–¹æ¡ˆè¿›è¡Œ**ä¸¥æ ¼ã€æ·±å…¥çš„æŠ€æœ¯æ‰¹è¯„**ã€‚

ã€åŸå§‹é—®é¢˜ã€‘{problem}
ã€é—®é¢˜ç±»å‹ã€‘{intent.problem_type}

ã€å„ä¸“å®¶æ–¹æ¡ˆã€‘
{solutions_text}

ã€æ‰¹è¯„è¦æ±‚ã€‘
è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡ŒæŒ‘æˆ˜æ€§æ‰¹è¯„ï¼š
1. **æŠ€æœ¯å¯è¡Œæ€§**ï¼šæ–¹æ¡ˆæ˜¯å¦å­˜åœ¨æŠ€æœ¯æ¼æ´æˆ–ä¸å¯è¡Œä¹‹å¤„ï¼Ÿ
2. **å®Œæ•´æ€§**ï¼šæ˜¯å¦æœ‰é‡è¦å› ç´ è¢«é—æ¼ï¼Ÿ
3. **æˆæœ¬æ•ˆç›Š**ï¼šæ–¹æ¡ˆçš„æŠ•å…¥äº§å‡ºæ¯”æ˜¯å¦åˆç†ï¼Ÿ
4. **é£é™©**ï¼šæœ‰å“ªäº›æ½œåœ¨é£é™©æ²¡æœ‰è¢«å……åˆ†è€ƒè™‘ï¼Ÿ
5. **åˆ›æ–°æ€§**ï¼šæ˜¯å¦æœ‰æ›´å¥½çš„æ›¿ä»£æ–¹æ¡ˆï¼Ÿ

è¯·ç»™å‡ºå°–é”ä½†ä¸“ä¸šçš„æ‰¹è¯„ï¼ˆ300å­—ï¼‰ï¼š"""
        
        try:
            critique = await self.llm_client.get_completion_async(
                system_prompt="ä½ æ˜¯ä¸¥æ ¼çš„æŠ€æœ¯è¯„å®¡ä¸“å®¶ï¼Œå–„äºå‘ç°æ–¹æ¡ˆçš„é—®é¢˜å’Œæ¼æ´ã€‚è¯·ç›´æ¥æŒ‡å‡ºé—®é¢˜ï¼Œä¸è¦å®¢å¥—ã€‚",
                user_prompt=critique_prompt,
                model="gemini-3-pro-preview"
            )
        except Exception as e:
            critique = f"[æ‰¹è¯„ç”Ÿæˆå¤±è´¥] {str(e)}"
        
        # 2. å„ä¸“å®¶å›åº”æ‰¹è¯„
        responses = []
        for expert, solution in zip(experts, solutions):
            response_prompt = f"""ã€å›åº”æŠ€æœ¯æ‰¹è¯„ã€‘

ä½ æ˜¯{expert.name}ï¼Œä½ çš„æ–¹æ¡ˆå—åˆ°äº†ä»¥ä¸‹æ‰¹è¯„ï¼š

ã€æ‰¹è¯„å†…å®¹ã€‘
{critique}

ã€ä½ çš„åŸæ–¹æ¡ˆæ‘˜è¦ã€‘
{solution.solution[:400]}

è¯·å›åº”è¿™äº›æ‰¹è¯„ï¼Œè¯´æ˜ï¼š
1. å“ªäº›æ‰¹è¯„æœ‰é“ç†ï¼Œä½ ä¼šå¦‚ä½•æ”¹è¿›
2. å“ªäº›æ‰¹è¯„å¯èƒ½å­˜åœ¨è¯¯è§£ï¼Œä½ å¦‚ä½•è§£é‡Š
3. è¡¥å……ä»»ä½•ä¹‹å‰é—æ¼çš„è€ƒè™‘

è¯·ç»™å‡ºä½ çš„å›åº”ï¼ˆ200å­—ï¼‰ï¼š"""
            
            try:
                response = await self.llm_client.get_completion_async(
                    system_prompt=f"ä½ æ˜¯{expert.role}ï¼Œæ­£åœ¨å›åº”æŠ€æœ¯æ‰¹è¯„ã€‚ä¿æŒä¸“ä¸šï¼Œæ‰¿è®¤åˆç†æ‰¹è¯„ï¼Œä½†ä¹Ÿè¦ä¸ºåˆç†çš„è®¾è®¡å†³ç­–è¾©æŠ¤ã€‚",
                    user_prompt=response_prompt,
                    model="gemini-3-pro-preview"
                )
                responses.append({
                    "expert": expert.name,
                    "response": response
                })
            except Exception as e:
                responses.append({
                    "expert": expert.name,
                    "response": f"[å›åº”å¤±è´¥] {str(e)}"
                })
        
        return {
            "critique": critique,
            "responses": responses
        }
    
    async def _run_evaluation(
        self,
        problem: str,
        intent: ProblemIntent,
        solutions: List[SubProblemSolution],
        discussions: List[dict],
        critique_result: dict
    ) -> dict:
        """
        å¤šç»´åº¦è¯„ä¼° - å¯¹è®¨è®ºåçš„æ–¹æ¡ˆè¿›è¡Œç»¼åˆè¯„ä¼°
        
        Returns:
            {
                "dimensions": {"feasibility": N, "risk": N, "cost": N, "innovation": N},
                "ranking": ["expert1", "expert2", ...],
                "summary": str
            }
        """
        # æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡
        solutions_text = "\n".join([
            f"ã€{s.expert_name}ã€‘{s.solution[:300]}"
            for s in solutions
        ])
        
        discussions_text = "\n".join([
            f"ã€{d['expert']}è®¨è®ºã€‘{d['comment'][:200]}"
            for d in discussions
        ]) if discussions else "æ— è®¨è®ºè®°å½•"
        
        prompt = f"""ã€æŠ€æœ¯æ–¹æ¡ˆç»¼åˆè¯„ä¼°ã€‘

è¯·å¯¹ä»¥ä¸‹æŠ€æœ¯æ–¹æ¡ˆè¿›è¡Œå¤šç»´åº¦è¯„ä¼°ã€‚

ã€é—®é¢˜ã€‘{problem}

ã€å„ä¸“å®¶æ–¹æ¡ˆã€‘
{solutions_text}

ã€ä¸“å®¶è®¨è®ºè¦ç‚¹ã€‘
{discussions_text}

ã€æ‰¹è¯„ä¸å›åº”ã€‘
{critique_result.get('critique', 'æ— ')[:300]}

ã€è¯„ä¼°è¦æ±‚ã€‘
è¯·è¾“å‡ºJSONæ ¼å¼è¯„ä¼°ç»“æœï¼š
{{
    "feasibility": {{
        "score": 0-100,
        "comment": "å¯è¡Œæ€§è¯„ä»·"
    }},
    "risk": {{
        "score": 0-100,  // åˆ†æ•°è¶Šé«˜é£é™©è¶Šä½
        "comment": "é£é™©è¯„ä»·"
    }},
    "cost": {{
        "score": 0-100,  // åˆ†æ•°è¶Šé«˜æˆæœ¬è¶Šä½
        "comment": "æˆæœ¬è¯„ä»·"
    }},
    "innovation": {{
        "score": 0-100,
        "comment": "åˆ›æ–°æ€§è¯„ä»·"
    }},
    "ranking": ["æ–¹æ¡ˆæœ€ä¼˜çš„ä¸“å®¶å", "ç¬¬äºŒ...", "..."],
    "overall_score": 0-100,
    "recommendation": "æœ€ç»ˆæ¨èæ„è§ï¼ˆ100å­—ï¼‰"
}}

è¯·åªè¾“å‡ºJSONï¼š"""
        
        try:
            result = await self.llm_client.get_completion_async(
                system_prompt="ä½ æ˜¯æŠ€æœ¯æ–¹æ¡ˆè¯„ä¼°ä¸“å®¶ï¼Œè¯·è¾“å‡ºä¸¥æ ¼çš„JSONæ ¼å¼è¯„ä¼°ç»“æœã€‚",
                user_prompt=prompt,
                model="gemini-3-pro-preview"
            )
            # å°è¯•è§£æJSON
            import re
            json_match = re.search(r'\{[\s\S]*\}', result)
            if json_match:
                try:
                    return json.loads(json_match.group())
                except:
                    pass
            return {
                "overall_score": 75,
                "recommendation": "æ–¹æ¡ˆæ€»ä½“å¯è¡Œï¼Œå»ºè®®ç»¼åˆå„ä¸“å®¶æ„è§å®æ–½ã€‚"
            }
        except Exception as e:
            return {
                "overall_score": 70,
                "recommendation": f"è¯„ä¼°å¤±è´¥: {str(e)}"
            }

